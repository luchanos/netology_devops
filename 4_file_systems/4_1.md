1. Узнайте о sparse-файлах (разряженных).

Прочитал википедию и пару статей.

2. Могут ли файлы, являющиеся жёсткой ссылкой на один объект, иметь разные права доступа и владельца? Почему?

Нет не могут. Потому что в Unix-подобных операционных системах жёсткая ссылка на файл — это просто указатель на
область диска, где хранятся данные. Информация о владельце, правах доступа и других атрибутах хранится
в inode (индексный узел) файла, а не в ссылке на файл. По сути, все жёсткие ссылки на файл указывают на один и тот же
inode, поэтому они не могут иметь различных прав доступа или владельцев. Это отличает их от символических ссылок, 
которые могут указывать на разные файлы и иметь разные права доступа.

3. Сделайте vagrant destroy на имеющийся инстанс Ubuntu. Замените содержимое Vagrantfile следующим:

path_to_disk_folder = './disks'

host_params = {
    'disk_size' => 2560,
    'disks'=>[1, 2],
    'cpus'=>2,
    'memory'=>2048,
    'hostname'=>'sysadm-fs',
    'vm_name'=>'sysadm-fs'
}
Vagrant.configure("2") do |config|
    config.vm.box = "bento/ubuntu-20.04"
    config.vm.hostname=host_params['hostname']
    config.vm.provider :virtualbox do |v|

        v.name=host_params['vm_name']
        v.cpus=host_params['cpus']
        v.memory=host_params['memory']

        host_params['disks'].each do |disk|
            file_to_disk=path_to_disk_folder+'/disk'+disk.to_s+'.vdi'
            unless File.exist?(file_to_disk)
                v.customize ['createmedium', '--filename', file_to_disk, '--size', host_params['disk_size']]
                v.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', disk.to_s, '--device', 0, '--type', 'hdd', '--medium', file_to_disk]
            end
        end
    end
    config.vm.network "private_network", type: "dhcp"
end
Эта конфигурация создаст новую виртуальную машину с двумя дополнительными неразмеченными дисками по 2,5 Гб.

Скопируйте код Vagrantfile в файл с именем Vagrantfile в выбранной вами директории.

- Я создал папку disks.
- Перешел в неё и выполнил команду vagrant up.
- У меня появилась новая виртуальная машина Ubuntu с двумя дополнительными дисками.
- Я великолепен

4. Используя fdisk, разбейте первый диск на два раздела: 2 Гб и оставшееся пространство.
- открыл fdisk `sudo fdisk /dev/sdb`
- создал новую доску разделов: g -> Enter
- создал первый раздел размером 2 ГБ, нажав n -> Enter 4 раза (default settings), затем выбрал +2G, чтобы задать размер
- создал второй раздел, нажав n -> 3 три раза (default settings)
- сохраняем и выходим (w)

5. Используя sfdisk, перенесите эту таблицу разделов на второй диск.
- создаю дамп разделов на первом диске через `sudo sfdisk -d /dev/sdb > partitions.sfdisk`
- применяю таблицу разделов к второму диску через `sudo sfdisk /dev/sdc < partitions.sfdisk`

6. Соберите mdadm RAID1 на паре разделов 2 Гб.
- использую команду `sudo mdadm --create --verbose /dev/md0 --level=1 --raid-devices=2 /dev/sdb1 /dev/sdc1`

7. Соберите mdadm RAID0 на второй паре маленьких разделов.
- использую команду `sudo mdadm --create --verbose /dev/md1 --level=0 --raid-devices=2 /dev/sdb2 /dev/sdc2`

8. Создайте два независимых PV на получившихся md-устройствах.
Создаю физические тома с помощью pvcreate:
`sudo pvcreate /dev/md0
sudo pvcreate /dev/md1
`
9. Создайте общую volume-group на этих двух PV.
`sudo vgcreate myvg /dev/md0 /dev/md1`

10. Создайте LV размером 100 Мб, указав его расположение на PV с RAID0.
`sudo lvcreate --size 100M --name mylv myvg /dev/md1`

11. Создайте mkfs.ext4 ФС на получившемся LV.
`sudo mkfs.ext4 /dev/myvg/mylv`

12. Смонтируйте этот раздел в любую директорию, например, /tmp/new.
`sudo mkdir /tmp/new
sudo mount /dev/myvg/mylv /tmp/new
`

13. Поместите туда тестовый файл, например, wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz.
`sudo wget https://mirror.yandex.ru/ubuntu/ls-lR.gz -O /tmp/new/test.gz`

14. Прикрепите вывод lsblk.

```
NAME              MAJ:MIN RM   SIZE RO TYPE  MOUNTPOINT
sda                 8:0    0    10G  0 disk  
└─sda1              8:1    0    10G  0 part  /
sdb                 8:16   0   2.5G  0 disk  
├─sdb1              8:17   0     2G  0 part  
│ └─md0             9:0    0     2G  0 raid1 
│   └─myvg-mylv0  253:0    0   100M  0 lvm   /tmp/new
└─sdb2              8:18   0   512M  0 part  
  └─md1             9:1    0 1018M  0 raid0 
sdc                 8:32   0   2.5G  0 disk  
├─sdc1              8:33   0     2G  0 part  
│ └─md0             9:0    0     2G  0 raid1 
│   └─myvg-mylv0  253:0    0   100M  0 lvm   /tmp/new
└─sdc2              8:34   0   512M  0 part  
  └─md1             9:1    0 1018M  0 raid0
```

15. Протестируйте целостность файла:
```
root@vagrant:~# gzip -t /tmp/new/test.gz
root@vagrant:~# echo $?
0
```

Целостность протестирована без ошибок

16. Используя pvmove, переместите содержимое PV с RAID0 на RAID1.
```sudo pvmove /dev/md1 /dev/md0```

17. Сделайте --fail на устройство в вашем RAID1 md.
```sudo mdadm --manage /dev/md0 --fail /dev/sdb1```

18. Подтверждение выводом dmesg, что RAID1 работает в деградированном состоянии:
```
[  376.563448] md/raid1:md0: Disk failure on sdb1, disabling device.
[  376.563448] md/raid1:md0: Operation continuing on 1 devices.
```

19. Протестируйте целостность файла — он должен быть доступен несмотря на «сбойный» диск:
протестирован, доступен
20. Погасите тестовый хост — vagrant destroy
Собственно, погасил. Добавил ещё флаг -f